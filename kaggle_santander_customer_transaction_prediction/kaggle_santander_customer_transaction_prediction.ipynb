{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santander Customer Transaction Prediction\n",
    "\n",
    "Link: https://www.kaggle.com/competitions/santander-customer-transaction-prediction/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../santander-customer-transaction-prediction/train.csv\")\n",
    "test = pd.read_csv(\"../santander-customer-transaction-prediction/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052390</td>\n",
       "      <td>0.050343</td>\n",
       "      <td>0.055870</td>\n",
       "      <td>0.011055</td>\n",
       "      <td>0.010915</td>\n",
       "      <td>0.030979</td>\n",
       "      <td>0.066731</td>\n",
       "      <td>0.003025</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055973</td>\n",
       "      <td>0.047114</td>\n",
       "      <td>0.042858</td>\n",
       "      <td>0.017709</td>\n",
       "      <td>0.022838</td>\n",
       "      <td>0.028285</td>\n",
       "      <td>0.023608</td>\n",
       "      <td>0.035303</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>0.025434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_0</th>\n",
       "      <td>0.052390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.003850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_1</th>\n",
       "      <td>0.050343</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003980</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006627</td>\n",
       "      <td>0.003621</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>0.002287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_2</th>\n",
       "      <td>0.055870</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.003980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>0.003952</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.003855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_3</th>\n",
       "      <td>0.011055</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.003553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.001651</td>\n",
       "      <td>0.000506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_195</th>\n",
       "      <td>0.028285</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.004745</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002517</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.002042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_196</th>\n",
       "      <td>0.023608</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.003952</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>0.005040</td>\n",
       "      <td>0.002517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_197</th>\n",
       "      <td>0.035303</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>0.003466</td>\n",
       "      <td>0.004583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004974</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.004991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_198</th>\n",
       "      <td>0.053000</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.001651</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.003025</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.002950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.003194</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_199</th>\n",
       "      <td>0.025434</td>\n",
       "      <td>0.003850</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>0.003855</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.006096</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.003595</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.005615</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.004991</td>\n",
       "      <td>0.004731</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           target     var_0     var_1     var_2     var_3     var_4     var_5  \\\n",
       "target   1.000000  0.052390  0.050343  0.055870  0.011055  0.010915  0.030979   \n",
       "var_0    0.052390  1.000000  0.000544  0.006573  0.003801  0.001326  0.003046   \n",
       "var_1    0.050343  0.000544  1.000000  0.003980  0.000010  0.000303  0.000902   \n",
       "var_2    0.055870  0.006573  0.003980  1.000000  0.001001  0.000723  0.001569   \n",
       "var_3    0.011055  0.003801  0.000010  0.001001  1.000000  0.000322  0.003253   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "var_195  0.028285  0.002073  0.000785  0.001070  0.001206  0.003706  0.001274   \n",
       "var_196  0.023608  0.004386  0.000377  0.003952  0.002800  0.000513  0.002880   \n",
       "var_197  0.035303  0.000753  0.004157  0.001078  0.001164  0.000046  0.000535   \n",
       "var_198  0.053000  0.005776  0.004861  0.000877  0.001651  0.001821  0.000953   \n",
       "var_199  0.025434  0.003850  0.002287  0.003855  0.000506  0.000786  0.002767   \n",
       "\n",
       "            var_6     var_7     var_8  ...   var_190   var_191   var_192  \\\n",
       "target   0.066731  0.003025  0.019584  ...  0.055973  0.047114  0.042858   \n",
       "var_0    0.006983  0.002429  0.004962  ...  0.002752  0.000206  0.005373   \n",
       "var_1    0.003258  0.001511  0.004098  ...  0.006627  0.003621  0.002604   \n",
       "var_2    0.000883  0.000991  0.002648  ...  0.000197  0.001285  0.003400   \n",
       "var_3    0.000774  0.002500  0.003553  ...  0.000151  0.002445  0.001530   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "var_195  0.001244  0.001854  0.001396  ...  0.004571  0.000870  0.004745   \n",
       "var_196  0.005378  0.001045  0.003242  ...  0.000847  0.002466  0.001386   \n",
       "var_197  0.003565  0.003466  0.004583  ...  0.004974  0.000906  0.000527   \n",
       "var_198  0.003025  0.000650  0.002950  ...  0.000153  0.000067  0.003451   \n",
       "var_199  0.006096  0.001457  0.000854  ...  0.000404  0.003595  0.001239   \n",
       "\n",
       "          var_193   var_194   var_195   var_196   var_197   var_198   var_199  \n",
       "target   0.017709  0.022838  0.028285  0.023608  0.035303  0.053000  0.025434  \n",
       "var_0    0.001616  0.001514  0.002073  0.004386  0.000753  0.005776  0.003850  \n",
       "var_1    0.001153  0.002557  0.000785  0.000377  0.004157  0.004861  0.002287  \n",
       "var_2    0.000549  0.002104  0.001070  0.003952  0.001078  0.000877  0.003855  \n",
       "var_3    0.001699  0.001054  0.001206  0.002800  0.001164  0.001651  0.000506  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "var_195  0.003143  0.001201  1.000000  0.002517  0.004170  0.000536  0.002042  \n",
       "var_196  0.005308  0.005040  0.002517  1.000000  0.000454  0.000253  0.000607  \n",
       "var_197  0.005068  0.000884  0.004170  0.000454  1.000000  0.001183  0.004991  \n",
       "var_198  0.001646  0.003194  0.000536  0.000253  0.001183  1.000000  0.004731  \n",
       "var_199  0.000552  0.005615  0.002042  0.000607  0.004991  0.004731  1.000000  \n",
       "\n",
       "[201 rows x 201 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only numeric columns from the DataFrame before calculating correlation\n",
    "numeric_columns = train.select_dtypes(include=['number'])\n",
    "correlation_matrix = numeric_columns.corr().abs()\n",
    "correlation_matrix # Low correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 91/200 [00:01<00:01, 59.69it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      " 50%|████▉     | 99/200 [00:01<00:01, 63.31it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      " 53%|█████▎    | 106/200 [00:01<00:01, 63.71it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      " 56%|█████▋    | 113/200 [00:01<00:01, 61.43it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      " 60%|██████    | 120/200 [00:01<00:01, 58.96it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      " 63%|██████▎   | 126/200 [00:02<00:01, 57.23it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      " 66%|██████▌   | 132/200 [00:02<00:01, 46.89it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      " 68%|██████▊   | 137/200 [00:02<00:01, 46.38it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      " 71%|███████   | 142/200 [00:02<00:01, 45.09it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      " 74%|███████▎  | 147/200 [00:02<00:01, 44.98it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      " 76%|███████▌  | 152/200 [00:02<00:01, 45.74it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      " 79%|███████▉  | 158/200 [00:02<00:00, 46.83it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      " 82%|████████▏ | 164/200 [00:02<00:00, 48.19it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      " 84%|████████▍ | 169/200 [00:03<00:00, 44.89it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      " 88%|████████▊ | 175/200 [00:03<00:00, 46.51it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      " 90%|█████████ | 180/200 [00:03<00:00, 47.37it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      " 92%|█████████▎| 185/200 [00:03<00:00, 47.11it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      " 96%|█████████▌| 191/200 [00:03<00:00, 48.33it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      " 98%|█████████▊| 197/200 [00:03<00:00, 50.39it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/607844094.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[col + \"_u\"] = test[col].isin(uniques)\n",
      "100%|██████████| 200/200 [00:03<00:00, 54.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# Checking uniqueness of features, saw on forum that some test samples where just combinations of values from other rows\n",
    "col_names = [f'var_{i}' for i in range(200)]\n",
    "for col in tqdm(col_names):\n",
    "    count = test[col].value_counts()\n",
    "    uniques = count.index[count == 1]\n",
    "    test[col + \"_u\"] = test[col].isin(uniques)\n",
    "\n",
    "test[\"has_unique\"] = test[[col + \"_u\" for col in col_names]].any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         False\n",
       "1         False\n",
       "2         False\n",
       "3          True\n",
       "4         False\n",
       "          ...  \n",
       "199995    False\n",
       "199996    False\n",
       "199997    False\n",
       "199998    False\n",
       "199999    False\n",
       "Name: var_0_u, Length: 200000, dtype: bool"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"var_0_u\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"has_unique\"].sum() # 100 000 real, rest fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'has_unique'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/py39-mac/lib/python3.9/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/py39-mac/lib/python3.9/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39-mac/lib/python3.9/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'has_unique'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/eriklarsson/git/PyTorch/kaggle_santander_customer_transaction_prediction/kaggle_santander_customer_transaction_prediction.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/eriklarsson/git/PyTorch/kaggle_santander_customer_transaction_prediction/kaggle_santander_customer_transaction_prediction.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m real_test \u001b[39m=\u001b[39m test\u001b[39m.\u001b[39mloc[test[\u001b[39m\"\u001b[39;49m\u001b[39mhas_unique\u001b[39;49m\u001b[39m\"\u001b[39;49m], [\u001b[39m\"\u001b[39m\u001b[39mID_code\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m col_names]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/eriklarsson/git/PyTorch/kaggle_santander_customer_transaction_prediction/kaggle_santander_customer_transaction_prediction.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m fake_test \u001b[39m=\u001b[39m test\u001b[39m.\u001b[39mloc[\u001b[39m~\u001b[39mtest[\u001b[39m\"\u001b[39m\u001b[39mhas_unique\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mID_code\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m col_names]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/eriklarsson/git/PyTorch/kaggle_santander_customer_transaction_prediction/kaggle_santander_customer_transaction_prediction.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_and_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([train, real_test], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39-mac/lib/python3.9/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/py39-mac/lib/python3.9/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'has_unique'"
     ]
    }
   ],
   "source": [
    "real_test = test.loc[test[\"has_unique\"], [\"ID_code\"] + col_names]\n",
    "fake_test = test.loc[~test[\"has_unique\"], [\"ID_code\"] + col_names]\n",
    "train_and_test = pd.concat([train, real_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 97/200 [00:15<00:14,  7.00it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      " 49%|████▉     | 98/200 [00:15<00:15,  6.39it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 50%|████▉     | 99/200 [00:15<00:14,  6.81it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 50%|█████     | 100/200 [00:15<00:15,  6.66it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 50%|█████     | 101/200 [00:16<00:16,  6.05it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 51%|█████     | 102/200 [00:16<00:16,  5.90it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 52%|█████▏    | 103/200 [00:16<00:17,  5.64it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 52%|█████▏    | 104/200 [00:16<00:15,  6.33it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 52%|█████▎    | 105/200 [00:16<00:14,  6.53it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 53%|█████▎    | 106/200 [00:16<00:13,  7.02it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 54%|█████▎    | 107/200 [00:16<00:13,  6.90it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 54%|█████▍    | 108/200 [00:17<00:14,  6.29it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 55%|█████▍    | 109/200 [00:17<00:13,  6.97it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 55%|█████▌    | 110/200 [00:17<00:14,  6.40it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 56%|█████▌    | 111/200 [00:17<00:14,  6.20it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 56%|█████▌    | 112/200 [00:17<00:13,  6.38it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 56%|█████▋    | 113/200 [00:17<00:13,  6.59it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 57%|█████▋    | 114/200 [00:18<00:13,  6.33it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 57%|█████▊    | 115/200 [00:18<00:12,  6.66it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 58%|█████▊    | 116/200 [00:18<00:12,  6.60it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 58%|█████▊    | 117/200 [00:18<00:12,  6.69it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 59%|█████▉    | 118/200 [00:18<00:13,  6.16it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 60%|█████▉    | 119/200 [00:18<00:13,  6.04it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 60%|██████    | 120/200 [00:18<00:12,  6.28it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 60%|██████    | 121/200 [00:19<00:13,  6.00it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 61%|██████    | 122/200 [00:19<00:12,  6.38it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 62%|██████▏   | 123/200 [00:19<00:12,  6.17it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 62%|██████▏   | 124/200 [00:19<00:12,  5.85it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 62%|██████▎   | 125/200 [00:19<00:12,  5.97it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 63%|██████▎   | 126/200 [00:19<00:11,  6.56it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 64%|██████▎   | 127/200 [00:20<00:10,  6.96it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 64%|██████▍   | 128/200 [00:20<00:10,  6.77it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 64%|██████▍   | 129/200 [00:20<00:10,  6.58it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 65%|██████▌   | 130/200 [00:20<00:10,  6.51it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 66%|██████▌   | 131/200 [00:20<00:09,  7.08it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 66%|██████▌   | 132/200 [00:20<00:08,  7.68it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 66%|██████▋   | 133/200 [00:20<00:08,  7.70it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 67%|██████▋   | 134/200 [00:21<00:08,  7.62it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 68%|██████▊   | 135/200 [00:21<00:09,  6.74it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 68%|██████▊   | 136/200 [00:21<00:10,  5.98it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 68%|██████▊   | 137/200 [00:21<00:11,  5.60it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 69%|██████▉   | 138/200 [00:21<00:11,  5.45it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 70%|██████▉   | 139/200 [00:21<00:11,  5.54it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 70%|███████   | 140/200 [00:22<00:10,  5.47it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 70%|███████   | 141/200 [00:22<00:10,  5.71it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 71%|███████   | 142/200 [00:22<00:09,  5.82it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 72%|███████▏  | 143/200 [00:22<00:09,  5.82it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 72%|███████▏  | 144/200 [00:22<00:09,  6.14it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 72%|███████▎  | 145/200 [00:22<00:08,  6.57it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 73%|███████▎  | 146/200 [00:23<00:08,  6.53it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 74%|███████▎  | 147/200 [00:23<00:08,  6.42it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 74%|███████▍  | 148/200 [00:23<00:08,  5.92it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 74%|███████▍  | 149/200 [00:23<00:07,  6.57it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 75%|███████▌  | 150/200 [00:23<00:08,  6.10it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 76%|███████▌  | 151/200 [00:23<00:07,  6.18it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 76%|███████▌  | 152/200 [00:24<00:07,  6.10it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 76%|███████▋  | 153/200 [00:24<00:07,  6.15it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 77%|███████▋  | 154/200 [00:24<00:07,  6.34it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 78%|███████▊  | 155/200 [00:24<00:07,  6.34it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 78%|███████▊  | 156/200 [00:24<00:06,  6.35it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 78%|███████▊  | 157/200 [00:24<00:06,  6.82it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 79%|███████▉  | 158/200 [00:25<00:06,  6.29it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 80%|███████▉  | 159/200 [00:25<00:07,  5.66it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 80%|████████  | 160/200 [00:25<00:07,  5.62it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 80%|████████  | 161/200 [00:25<00:07,  5.36it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 81%|████████  | 162/200 [00:25<00:06,  6.04it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 82%|████████▏ | 163/200 [00:25<00:05,  6.35it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 82%|████████▏ | 164/200 [00:26<00:05,  6.14it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 82%|████████▎ | 165/200 [00:26<00:05,  6.05it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 83%|████████▎ | 166/200 [00:26<00:05,  6.13it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 84%|████████▎ | 167/200 [00:26<00:04,  6.76it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 84%|████████▍ | 168/200 [00:26<00:05,  6.30it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 84%|████████▍ | 169/200 [00:26<00:04,  6.39it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 85%|████████▌ | 170/200 [00:26<00:04,  6.86it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 86%|████████▌ | 171/200 [00:27<00:04,  6.38it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 86%|████████▌ | 172/200 [00:27<00:04,  6.07it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 86%|████████▋ | 173/200 [00:27<00:04,  5.66it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 87%|████████▋ | 174/200 [00:27<00:04,  5.67it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 88%|████████▊ | 175/200 [00:27<00:04,  5.70it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 88%|████████▊ | 176/200 [00:28<00:03,  6.02it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 88%|████████▊ | 177/200 [00:28<00:03,  5.95it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 89%|████████▉ | 178/200 [00:28<00:03,  6.27it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 90%|████████▉ | 179/200 [00:28<00:03,  5.92it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 90%|█████████ | 180/200 [00:28<00:03,  6.02it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 90%|█████████ | 181/200 [00:28<00:03,  5.90it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 91%|█████████ | 182/200 [00:29<00:02,  6.12it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 92%|█████████▏| 183/200 [00:29<00:02,  5.70it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 92%|█████████▏| 184/200 [00:29<00:02,  5.76it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 92%|█████████▎| 185/200 [00:29<00:02,  5.51it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 93%|█████████▎| 186/200 [00:29<00:02,  5.48it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 94%|█████████▎| 187/200 [00:29<00:02,  5.67it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 94%|█████████▍| 188/200 [00:30<00:02,  5.43it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 94%|█████████▍| 189/200 [00:30<00:01,  5.57it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 95%|█████████▌| 190/200 [00:30<00:01,  6.03it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 96%|█████████▌| 191/200 [00:30<00:01,  5.94it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 96%|█████████▌| 192/200 [00:30<00:01,  5.96it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 96%|█████████▋| 193/200 [00:30<00:01,  6.16it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 97%|█████████▋| 194/200 [00:31<00:00,  6.03it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 98%|█████████▊| 195/200 [00:31<00:00,  6.00it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 98%|█████████▊| 196/200 [00:31<00:00,  6.34it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 98%|█████████▊| 197/200 [00:31<00:00,  6.09it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      " 99%|█████████▉| 198/200 [00:31<00:00,  6.43it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      "100%|█████████▉| 199/200 [00:31<00:00,  6.40it/s]/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
      "/var/folders/sb/kwsrvht9349616l5vqmptz540000gn/T/ipykernel_51368/444832406.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fake_test[col + \"_unique\"] = 0\n",
      "100%|██████████| 200/200 [00:32<00:00,  6.23it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(col_names):\n",
    "    count = train_and_test[col].value_counts().to_dict()\n",
    "    train_and_test[col + \"_unique\"] = train_and_test[col].apply(lambda x: 1 if count[x] == 1 else 0).values\n",
    "    fake_test[col + \"_unique\"] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_unique</th>\n",
       "      <th>var_191_unique</th>\n",
       "      <th>var_192_unique</th>\n",
       "      <th>var_193_unique</th>\n",
       "      <th>var_194_unique</th>\n",
       "      <th>var_195_unique</th>\n",
       "      <th>var_196_unique</th>\n",
       "      <th>var_197_unique</th>\n",
       "      <th>var_198_unique</th>\n",
       "      <th>var_199_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199986</th>\n",
       "      <td>test_199986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.2884</td>\n",
       "      <td>-2.8384</td>\n",
       "      <td>11.9149</td>\n",
       "      <td>6.6611</td>\n",
       "      <td>12.3112</td>\n",
       "      <td>12.9244</td>\n",
       "      <td>5.6492</td>\n",
       "      <td>16.0449</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199993</th>\n",
       "      <td>test_199993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.6764</td>\n",
       "      <td>-8.1066</td>\n",
       "      <td>7.1167</td>\n",
       "      <td>2.4138</td>\n",
       "      <td>10.3845</td>\n",
       "      <td>-11.9327</td>\n",
       "      <td>4.7563</td>\n",
       "      <td>16.0455</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>test_199995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.1678</td>\n",
       "      <td>1.0136</td>\n",
       "      <td>10.4333</td>\n",
       "      <td>6.7997</td>\n",
       "      <td>8.5974</td>\n",
       "      <td>-4.1641</td>\n",
       "      <td>4.8579</td>\n",
       "      <td>14.7625</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>test_199996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.7171</td>\n",
       "      <td>-9.1462</td>\n",
       "      <td>7.3443</td>\n",
       "      <td>9.1421</td>\n",
       "      <td>12.8936</td>\n",
       "      <td>3.0191</td>\n",
       "      <td>5.6888</td>\n",
       "      <td>18.8862</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>test_199999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.4664</td>\n",
       "      <td>1.8070</td>\n",
       "      <td>10.2277</td>\n",
       "      <td>6.0654</td>\n",
       "      <td>10.0258</td>\n",
       "      <td>1.0789</td>\n",
       "      <td>4.8879</td>\n",
       "      <td>14.4892</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID_code  target    var_0   var_1    var_2   var_3    var_4  \\\n",
       "0           train_0     0.0   8.9255 -6.7863  11.9081  5.0930  11.4607   \n",
       "1           train_1     0.0  11.5006 -4.1473  13.8588  5.3890  12.3622   \n",
       "2           train_2     0.0   8.6093 -2.7457  12.0805  7.8928  10.5825   \n",
       "3           train_3     0.0  11.0604 -2.1518   8.9522  7.1957  12.5846   \n",
       "4           train_4     0.0   9.8369 -1.4834  12.8746  6.6375  12.2772   \n",
       "...             ...     ...      ...     ...      ...     ...      ...   \n",
       "199986  test_199986     NaN  19.2884 -2.8384  11.9149  6.6611  12.3112   \n",
       "199993  test_199993     NaN  14.6764 -8.1066   7.1167  2.4138  10.3845   \n",
       "199995  test_199995     NaN  13.1678  1.0136  10.4333  6.7997   8.5974   \n",
       "199996  test_199996     NaN   9.7171 -9.1462   7.3443  9.1421  12.8936   \n",
       "199999  test_199999     NaN  10.4664  1.8070  10.2277  6.0654  10.0258   \n",
       "\n",
       "          var_5   var_6    var_7  ...  var_190_unique  var_191_unique  \\\n",
       "0       -9.2834  5.1187  18.6266  ...               0               0   \n",
       "1        7.0433  5.6208  16.5338  ...               0               0   \n",
       "2       -9.0837  6.9427  14.6155  ...               0               0   \n",
       "3       -1.8361  5.8428  14.9250  ...               0               0   \n",
       "4        2.4486  5.9405  19.2514  ...               0               0   \n",
       "...         ...     ...      ...  ...             ...             ...   \n",
       "199986  12.9244  5.6492  16.0449  ...               0               0   \n",
       "199993 -11.9327  4.7563  16.0455  ...               0               0   \n",
       "199995  -4.1641  4.8579  14.7625  ...               1               0   \n",
       "199996   3.0191  5.6888  18.8862  ...               1               0   \n",
       "199999   1.0789  4.8879  14.4892  ...               0               0   \n",
       "\n",
       "        var_192_unique  var_193_unique  var_194_unique  var_195_unique  \\\n",
       "0                    0               0               0               0   \n",
       "1                    0               0               0               0   \n",
       "2                    0               0               0               0   \n",
       "3                    0               0               0               0   \n",
       "4                    1               1               1               0   \n",
       "...                ...             ...             ...             ...   \n",
       "199986               0               0               0               0   \n",
       "199993               0               0               0               0   \n",
       "199995               0               0               1               0   \n",
       "199996               0               0               0               0   \n",
       "199999               0               0               0               0   \n",
       "\n",
       "        var_196_unique  var_197_unique  var_198_unique  var_199_unique  \n",
       "0                    0               0               0               0  \n",
       "1                    0               0               0               0  \n",
       "2                    0               0               0               0  \n",
       "3                    0               0               0               0  \n",
       "4                    0               0               0               0  \n",
       "...                ...             ...             ...             ...  \n",
       "199986               0               0               0               0  \n",
       "199993               0               0               0               1  \n",
       "199995               0               0               0               1  \n",
       "199996               0               0               0               1  \n",
       "199999               0               0               0               1  \n",
       "\n",
       "[300000 rows x 402 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test = train_and_test[train_and_test[\"ID_code\"].str.contains(\"test\")].copy()\n",
    "real_test.drop([\"target\"], axis=1, inplace=True)\n",
    "train = train_and_test[train_and_test[\"ID_code\"].str.contains(\"train\")].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([real_test, fake_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"new_train.csv\", index=False)\n",
    "test.to_csv(\"new_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_unique</th>\n",
       "      <th>var_191_unique</th>\n",
       "      <th>var_192_unique</th>\n",
       "      <th>var_193_unique</th>\n",
       "      <th>var_194_unique</th>\n",
       "      <th>var_195_unique</th>\n",
       "      <th>var_196_unique</th>\n",
       "      <th>var_197_unique</th>\n",
       "      <th>var_198_unique</th>\n",
       "      <th>var_199_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>train_199995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.4880</td>\n",
       "      <td>-0.4956</td>\n",
       "      <td>8.2622</td>\n",
       "      <td>3.5142</td>\n",
       "      <td>10.3404</td>\n",
       "      <td>11.6081</td>\n",
       "      <td>5.6709</td>\n",
       "      <td>15.1516</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>train_199996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9149</td>\n",
       "      <td>-2.4484</td>\n",
       "      <td>16.7052</td>\n",
       "      <td>6.6345</td>\n",
       "      <td>8.3096</td>\n",
       "      <td>-10.5628</td>\n",
       "      <td>5.8802</td>\n",
       "      <td>21.5940</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>train_199997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.2232</td>\n",
       "      <td>-5.0518</td>\n",
       "      <td>10.5127</td>\n",
       "      <td>5.6456</td>\n",
       "      <td>9.3410</td>\n",
       "      <td>-5.4086</td>\n",
       "      <td>4.5555</td>\n",
       "      <td>21.5571</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>train_199998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.7148</td>\n",
       "      <td>-8.6098</td>\n",
       "      <td>13.6104</td>\n",
       "      <td>5.7930</td>\n",
       "      <td>12.5173</td>\n",
       "      <td>0.5339</td>\n",
       "      <td>6.0479</td>\n",
       "      <td>17.0152</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>train_199999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.8762</td>\n",
       "      <td>-5.7105</td>\n",
       "      <td>12.1183</td>\n",
       "      <td>8.0328</td>\n",
       "      <td>11.5577</td>\n",
       "      <td>0.3488</td>\n",
       "      <td>5.2839</td>\n",
       "      <td>15.2058</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID_code  target    var_0   var_1    var_2   var_3    var_4  \\\n",
       "0            train_0     0.0   8.9255 -6.7863  11.9081  5.0930  11.4607   \n",
       "1            train_1     0.0  11.5006 -4.1473  13.8588  5.3890  12.3622   \n",
       "2            train_2     0.0   8.6093 -2.7457  12.0805  7.8928  10.5825   \n",
       "3            train_3     0.0  11.0604 -2.1518   8.9522  7.1957  12.5846   \n",
       "4            train_4     0.0   9.8369 -1.4834  12.8746  6.6375  12.2772   \n",
       "...              ...     ...      ...     ...      ...     ...      ...   \n",
       "199995  train_199995     0.0  11.4880 -0.4956   8.2622  3.5142  10.3404   \n",
       "199996  train_199996     0.0   4.9149 -2.4484  16.7052  6.6345   8.3096   \n",
       "199997  train_199997     0.0  11.2232 -5.0518  10.5127  5.6456   9.3410   \n",
       "199998  train_199998     0.0   9.7148 -8.6098  13.6104  5.7930  12.5173   \n",
       "199999  train_199999     0.0  10.8762 -5.7105  12.1183  8.0328  11.5577   \n",
       "\n",
       "          var_5   var_6    var_7  ...  var_190_unique  var_191_unique  \\\n",
       "0       -9.2834  5.1187  18.6266  ...               0               0   \n",
       "1        7.0433  5.6208  16.5338  ...               0               0   \n",
       "2       -9.0837  6.9427  14.6155  ...               0               0   \n",
       "3       -1.8361  5.8428  14.9250  ...               0               0   \n",
       "4        2.4486  5.9405  19.2514  ...               0               0   \n",
       "...         ...     ...      ...  ...             ...             ...   \n",
       "199995  11.6081  5.6709  15.1516  ...               0               1   \n",
       "199996 -10.5628  5.8802  21.5940  ...               0               0   \n",
       "199997  -5.4086  4.5555  21.5571  ...               0               0   \n",
       "199998   0.5339  6.0479  17.0152  ...               0               0   \n",
       "199999   0.3488  5.2839  15.2058  ...               0               0   \n",
       "\n",
       "        var_192_unique  var_193_unique  var_194_unique  var_195_unique  \\\n",
       "0                    0               0               0               0   \n",
       "1                    0               0               0               0   \n",
       "2                    0               0               0               0   \n",
       "3                    0               0               0               0   \n",
       "4                    1               1               1               0   \n",
       "...                ...             ...             ...             ...   \n",
       "199995               0               0               0               0   \n",
       "199996               0               1               0               0   \n",
       "199997               0               0               0               0   \n",
       "199998               0               0               0               0   \n",
       "199999               0               0               0               0   \n",
       "\n",
       "        var_196_unique  var_197_unique  var_198_unique  var_199_unique  \n",
       "0                    0               0               0               0  \n",
       "1                    0               0               0               0  \n",
       "2                    0               0               0               0  \n",
       "3                    0               0               0               0  \n",
       "4                    0               0               0               0  \n",
       "...                ...             ...             ...             ...  \n",
       "199995               1               0               0               0  \n",
       "199996               0               0               0               0  \n",
       "199997               0               0               0               1  \n",
       "199998               0               0               0               1  \n",
       "199999               0               0               0               1  \n",
       "\n",
       "[200000 rows x 402 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39-mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
